from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import undetected_chromedriver as uc
from datetime import datetime
import pickle
import time
import pandas as pd
import os

# ========================================
# ğŸ›ï¸ í¬ë¡¤ë§ ì„¤ì •
# ========================================
MAX_PAGES = 35
MAX_REVIEWS_PER_PRODUCT = 100
MAX_TAGS_PER_REVIEW = 5

PAGE_LOAD_WAIT = 3
PRODUCT_CLICK_WAIT = 2
REVIEW_TAB_WAIT = 2
BACK_WAIT = 2

UL_RANGE_START = 2
UL_RANGE_END = 8
LI_RANGE_START = 1
LI_RANGE_END = 5

HEADLESS_MODE = True
WINDOW_SIZE = "1920,1080"

# ========================================
# ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ì„¤ì •
# ========================================
# category_names = ['skincare', 'cleansing', 'suncare', 'menscare']
category_names = ['skincare']

prefixes = [
    '1000001000100',  # ìŠ¤í‚¨ì¼€ì–´
    # '1000001001000',  # í´ë Œì§•
    # '1000001001100',  # ì„ ì¼€ì–´
    # '1000001000700',  # ë§¨ì¦ˆì¼€ì–´
]
# ê° ì¹´í…Œê³ ë¦¬ë³„ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ì½”ë“œ ë° í‚¤ ì´ë¦„
subcategory_map = [
    [(15, 'cream')]
    # [(13, 'toner')], (14, 'serum'), (15, 'cream'), (16, 'lotion'), (10, 'mist_oil')],
    # [(1, 'foam_gel'), (4, 'oil_balm'), (5, 'water_milk'), (7, 'peeling_scrub')],
    # [(6, 'suncream'), (3, 'sunstick'), (4, 'suncushion'), (5, 'sunspray_patch')],
    # [(7, 'toner')]
]

# ========================================
# ğŸ€ Chrome Driver ì„¤ì • (undetected_chromedriver ì‚¬ìš©)
# ========================================
options = uc.ChromeOptions()
options.add_argument("--lang=ko-KR")
options.add_argument("--no-sandbox")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument('--disable-gpu')
options.add_argument(f'--window-size={WINDOW_SIZE}')
user_agent = (
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
    'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
)
options.add_argument(f'--user-agent={user_agent}')

if HEADLESS_MODE:
    options.add_argument('--headless=new')  # Chrome 109 ì´ìƒì—ì„œ ê¶Œì¥

driver = uc.Chrome(options=options)
print("âœ… í¬ë¡¬ ë“œë¼ì´ë²„(undetected) ì„¤ì • ì™„ë£Œ")


# ========================================
# ğŸª ì¿ í‚¤ ê´€ë ¨ í•¨ìˆ˜
# ========================================
def load_cookies():
    if os.path.exists("cookies.pkl"):
        driver.get("https://kr.iherb.com")
        with open("cookies.pkl", "rb") as f:
            cookies = pickle.load(f)
            for cookie in cookies:
                driver.add_cookie(cookie)
        driver.refresh()
        time.sleep(3)


def save_cookies():
    with open("cookies.pkl", "wb") as f:
        pickle.dump(driver.get_cookies(), f)


if not os.path.exists("cookies.pkl"):
    print("â— CAPTCHA í˜ì´ì§€ê°€ ë³´ì´ë©´ ìˆ˜ë™ìœ¼ë¡œ í’€ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    driver.get("https://kr.iherb.com")
    input("ğŸ‘‰ ìº¡ì°¨ë¥¼ í†µê³¼í–ˆìœ¼ë©´ Enter í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”...")
    save_cookies()
else:
    load_cookies()


# ========================================
# ğŸ·ï¸ íƒœê·¸ ë° ë¦¬ë·° ìˆ˜ì§‘ í•¨ìˆ˜
# ========================================
def collect_tags_and_review(r_idx):
    """
    íƒœê·¸ ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¼ ì ì ˆí•œ XPathë¡œ íƒœê·¸ì™€ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜
    """
    tags = []
    review = ""

    # ë¨¼ì € íƒœê·¸ê°€ ìˆëŠ”ì§€ í™•ì¸ (div[2]/div[2]ì—ì„œ íƒœê·¸ ìš”ì†Œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸)
    has_tags = False
    try:
        # íƒœê·¸ ì˜ì—­ì´ ìˆëŠ”ì§€ í™•ì¸
        tag_area_xpath = f'//*[@id="gdasList"]/li[{r_idx}]/div[2]/div[2]/dl[1]'
        driver.find_element(By.XPATH, tag_area_xpath)
        has_tags = True
        print(f"        ğŸ“ íƒœê·¸ ì˜ì—­ ë°œê²¬ (ë¦¬ë·° {r_idx})")
    except NoSuchElementException:
        print(f"        ğŸ“ íƒœê·¸ ì—†ìŒ (ë¦¬ë·° {r_idx})")

    if has_tags:
        # íƒœê·¸ê°€ ìˆëŠ” ê²½ìš°: íƒœê·¸ ìˆ˜ì§‘ í›„ div[3]ì—ì„œ ë¦¬ë·° ìˆ˜ì§‘
        for tag_idx in range(1, MAX_TAGS_PER_REVIEW + 1):
            try:
                tag_xpath = f'//*[@id="gdasList"]/li[{r_idx}]/div[2]/div[2]/dl[{tag_idx}]/dd/span'
                tag = driver.find_element(By.XPATH, tag_xpath).text.strip()
                if tag:  # ë¹ˆ íƒœê·¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                    tags.append(tag)
            except NoSuchElementException:
                break  # ë” ì´ìƒ íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨

        # ë¦¬ë·°ëŠ” div[3]ì—ì„œ ìˆ˜ì§‘
        try:
            review_xpath = f'//*[@id="gdasList"]/li[{r_idx}]/div[2]/div[3]'
            review = driver.find_element(By.XPATH, review_xpath).text.strip()
        except NoSuchElementException:
            print(f"        âŒ íƒœê·¸ ìˆëŠ” ë¦¬ë·°ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¦¬ë·° {r_idx})")
    else:
        # íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°: div[2]ì—ì„œ ë¦¬ë·° ìˆ˜ì§‘
        try:
            review_xpath = f'//*[@id="gdasList"]/li[{r_idx}]/div[2]/div[2]'
            review = driver.find_element(By.XPATH, review_xpath).text.strip()
        except NoSuchElementException:
            print(f"        âŒ íƒœê·¸ ì—†ëŠ” ë¦¬ë·°ì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¦¬ë·° {r_idx})")

    return tags, review


os.makedirs('./data', exist_ok=True)

# ========================================
# ğŸ”„ í¬ë¡¤ë§ ë£¨í”„ ì‹œì‘
# ========================================
total_start_time = time.time()
start_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘: {start_datetime}")
print(f"ğŸ›ï¸ ì„¤ì •: ìµœëŒ€ {MAX_PAGES}í˜ì´ì§€, ì œí’ˆë‹¹ {MAX_REVIEWS_PER_PRODUCT}ê°œ ë¦¬ë·°")

for idx in range(min(len(category_names), len(prefixes), len(subcategory_map))):
    category = category_names[idx]
    prefix = prefixes[idx]
    sub_list = subcategory_map[idx]

    category_start_time = time.time()

    for code, sub in sub_list:
        key = f"{category}_{sub}"
        # [ë³€ê²½] ê¸°ì¡´ category_data = [] ì œê±°í•˜ê³  CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
        csv_filepath = f'./data/{key}.csv'

        # [ë³€ê²½] CSV íŒŒì¼ ì´ˆê¸°í™” (í—¤ë”ë§Œ ì‘ì„±)
        df_header = pd.DataFrame(columns=['product', 'tag', 'review'])
        df_header.to_csv(csv_filepath, index=False, encoding='utf-8-sig')

        print(f"\nğŸ“ [{category} â†’ {sub}] í¬ë¡¤ë§ ì‹œì‘")
        # [ë³€ê²½] ì €ì¥ íŒŒì¼ ê²½ë¡œ ì¶œë ¥ ì¶”ê°€
        print(f"ğŸ’¾ ì €ì¥ íŒŒì¼: {csv_filepath}")
        current_page = 1

        while current_page <= MAX_PAGES:
            page_url = (
                f'https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?'
                f'dispCatNo={prefix}{code:02d}&fltDispCatNo=&prdSort=01&pageIdx={current_page}'
            )
            print(f"\nğŸŒ í˜ì´ì§€ {current_page}/{MAX_PAGES} ì ‘ì†: {page_url}")
            driver.get(page_url)
            time.sleep(PAGE_LOAD_WAIT)

            for ul_idx in range(UL_RANGE_START, UL_RANGE_END):
                for li_idx in range(LI_RANGE_START, LI_RANGE_END):
                    try:
                        xpath = (
                            f'//*[@id="Contents"]/ul[{ul_idx}]/li[{li_idx}]/div/div/a/p'
                        )
                        product_element = driver.find_element(By.XPATH, xpath)
                        name = product_element.text.strip()
                        print(f"    ğŸ” ì œí’ˆ ë°œê²¬: {name}")

                        # [ë³€ê²½] ì œí’ˆë³„ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±
                        product_data = []

                        driver.execute_script("arguments[0].click();", product_element)
                        time.sleep(PRODUCT_CLICK_WAIT)

                        try:
                            review_tab = WebDriverWait(driver, 16).until(
                                EC.element_to_be_clickable((By.CSS_SELECTOR, '#reviewInfo > a'))
                            )
                            review_tab.click()
                            time.sleep(REVIEW_TAB_WAIT)

                            try:
                                experience_checkbox = WebDriverWait(driver, 3).until(
                                    EC.element_to_be_clickable((By.CSS_SELECTOR, '#searchType div:nth-child(4) input'))
                                )
                                if experience_checkbox.is_selected():
                                    experience_checkbox.click()
                                    time.sleep(1)
                            except Exception:
                                pass

                            page_num = 1
                            reviews_collected = 0

                            while reviews_collected < MAX_REVIEWS_PER_PRODUCT:
                                for r_idx in range(1, MAX_REVIEWS_PER_PRODUCT + 1):
                                    if reviews_collected >= MAX_REVIEWS_PER_PRODUCT:
                                        break

                                    # ê°œì„ ëœ íƒœê·¸ ë° ë¦¬ë·° ìˆ˜ì§‘ í•¨ìˆ˜ ì‚¬ìš©
                                    tags, review = collect_tags_and_review(r_idx)

                                    if review:  # ë¦¬ë·°ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘ëœ ê²½ìš°ë§Œ ì €ì¥
                                        # [ë³€ê²½] category_data ëŒ€ì‹  product_dataì— ì¶”ê°€
                                        product_data.append({
                                            'product': name,
                                            'tag': ', '.join(tags) if tags else '',
                                            'review': review
                                        })
                                        reviews_collected += 1

                                        if tags:
                                            print(f"        ğŸ·ï¸ íƒœê·¸: {tags}")
                                        else:
                                            print(f"        ğŸ·ï¸ íƒœê·¸: ì—†ìŒ")
                                        print(
                                            f"        âœ… ë¦¬ë·° [{reviews_collected}/{MAX_REVIEWS_PER_PRODUCT}]: {review[:30]}...")
                                    else:
                                        # ë¦¬ë·°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ í•´ë‹¹ í˜ì´ì§€ì˜ ë¦¬ë·°ê°€ ëë‚œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                                        break

                                # ë‹¤ìŒ ë¦¬ë·° í˜ì´ì§€ë¡œ ì´ë™
                                page_num += 1
                                try:
                                    btn_css = f'#gdasContentsArea > div > div.pageing > a:nth-child({page_num})'
                                    page_btn = driver.find_element(By.CSS_SELECTOR, btn_css)
                                    page_btn.click()
                                    time.sleep(REVIEW_TAB_WAIT)
                                    print(f"        â–¶ï¸ ë¦¬ë·° í˜ì´ì§€ {page_num}ë¡œ ì´ë™")
                                except NoSuchElementException:
                                    print(f"        ğŸ”š ë” ì´ìƒ ë¦¬ë·° í˜ì´ì§€ê°€ ì—†ìŒ")
                                    break

                        except Exception as e:
                            print(f"      âŒ ë¦¬ë·° íƒ­ í´ë¦­ ë˜ëŠ” ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

                        # [ë³€ê²½] ì œí’ˆ ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ í›„ ì¦‰ì‹œ CSVì— ì¶”ê°€ ì €ì¥
                        if product_data:  # ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ìˆì„ ë•Œë§Œ
                            df_product = pd.DataFrame(product_data)
                            df_product.to_csv(csv_filepath, mode='a', header=False,
                                              index=False, encoding='utf-8-sig')

                            print(f"        ğŸ’¾ ì €ì¥ì™„ë£Œ: {name} ({len(product_data)}ê°œ ë¦¬ë·°)")

                            # [ë³€ê²½] ë©”ëª¨ë¦¬ ì •ë¦¬
                            del product_data, df_product

                        driver.back()
                        time.sleep(BACK_WAIT)

                    except NoSuchElementException:
                        continue

            current_page += 1

        # [ë³€ê²½] ê¸°ì¡´ DataFrame ìƒì„± ë° ì €ì¥ ì½”ë“œ ì œê±°, ì™„ë£Œëœ íŒŒì¼ í†µê³„ë¡œ ëŒ€ì²´
        try:
            final_df = pd.read_csv(csv_filepath, encoding='utf-8-sig')
            total_reviews = len(final_df)
            unique_products = final_df['product'].nunique()

            category_end_time = time.time()
            category_duration = category_end_time - category_start_time

            print(f"âœ… {key} ì™„ë£Œ: ì œí’ˆ {unique_products}ê°œ, ì´ ë¦¬ë·° {total_reviews}ê°œ")
            print(f"ğŸ’¾ íŒŒì¼ ì €ì¥: {csv_filepath}")
            print(f"â±ï¸ {key} ì†Œìš”ì‹œê°„: {category_duration:.1f}ì´ˆ ({category_duration / 60:.1f}ë¶„)")
        except Exception as e:
            print(f"âŒ {key} ì™„ë£Œ í†µê³„ ì¶œë ¥ ì˜¤ë¥˜: {e}")

# ========================================
# ğŸ“Š ìµœì¢… ê²°ê³¼ ì¶œë ¥
# ========================================
total_end_time = time.time()
total_duration = total_end_time - total_start_time
end_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

print(f"\nğŸ í¬ë¡¤ë§ ì™„ë£Œ: {end_datetime}")
print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_duration:.1f}ì´ˆ ({total_duration / 60:.1f}ë¶„)")
if total_duration >= 3600:
    print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_duration / 3600:.1f}ì‹œê°„")

print("\nğŸ›‘ ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
driver.quit()